{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201605e6-254b-4e78-8ac4-1d298ca494c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kfp-server-api=='0.5.0' --user\n",
    "# !pip install kfp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48c8d7e-385c-4e46-bafc-1cad3f99f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b039f9e6-c29e-45e3-8d35-d0c27c5428cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.notebook\n",
    "import kfp.components as comp\n",
    "from kfp import compiler\n",
    "from kfp.components import func_to_container_op, InputPath, OutputPath\n",
    "from kubernetes import client as k8s_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add2ca87-793c-4565-ad5d-8c81b747fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(out_dir: OutputPath(str),dataOrigin:str):\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    \n",
    "    dataURL = \"https://raw.githubusercontent.com/Durbek-Gafur/noshowdata/main/\"+dataOrigin\n",
    "    NoShowData = pd.read_csv(dataURL)\n",
    "    #Convert the variable \"Gender\" to category\n",
    "    NoShowData['Gender'] = NoShowData['Gender'].astype('category')\n",
    "\n",
    "    #Convert the variable \"DOW\" to category\n",
    "    NoShowData['DOW'] = NoShowData['DOW'].astype('category')\n",
    "\n",
    "    #Convert the variable \"SMS_received\" to category\n",
    "    NoShowData['SMS_received'] = NoShowData['SMS_received'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Scholarship\" to category\n",
    "    NoShowData['Scholarship'] = NoShowData['Scholarship'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Smoking_Status\" to category\n",
    "    NoShowData['Smoking_Status'] = NoShowData['Smoking_Status'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Hypertension\" to category\n",
    "    NoShowData['Hypertension'] = NoShowData['Hypertension'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Diabetes\" to category\n",
    "    NoShowData['Diabetes'] = NoShowData['Diabetes'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Alcoholism\" to category\n",
    "    NoShowData['Alcoholism'] = NoShowData['Alcoholism'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Tuberculosis\" to category\n",
    "    NoShowData['Tuberculosis'] = NoShowData['Tuberculosis'].astype('category')\n",
    "    \n",
    "    #Dummy code the columns\n",
    "    try:\n",
    "        NoShowData = pd.get_dummies(NoShowData,\n",
    "        columns=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\", \"Status\"],\n",
    "        prefix=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\", \"Status\"], \n",
    "                                 drop_first = True)\n",
    "    except:\n",
    "        NoShowData = pd.get_dummies(NoShowData,\n",
    "        columns=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\"],\n",
    "        prefix=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\"], \n",
    "                                 drop_first = True)\n",
    "    NoShowData.to_csv(out_dir, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e7f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectFeatureAndSplit(in_dir: InputPath(),\n",
    "                          x_train: OutputPath(str), \n",
    "                          x_test: OutputPath(str),\n",
    "                          y_train: OutputPath(str), \n",
    "                          y_test: OutputPath(str)):\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    NoShowData = pd.read_csv(in_dir)\n",
    "    NoShow_Predictors = pd.DataFrame(NoShowData.iloc[:,:-1])\n",
    "\n",
    "    NoShow_Outcome = pd.DataFrame(NoShowData.iloc[:,-1])\n",
    "    X_Train_NoShow, X_Test_NoShow, y_Train_NoShow, y_Test_NoShow = train_test_split(NoShow_Predictors, \n",
    "                                                                                    NoShow_Outcome, \n",
    "                                                                                    test_size=0.25, \n",
    "                                                                                    random_state=8810)\n",
    "    X_Train_NoShow.to_csv(x_train, index=False)\n",
    "    X_Test_NoShow.to_csv(x_test, index=False)\n",
    "    y_Train_NoShow.to_csv(y_train, index=False)\n",
    "    y_Test_NoShow.to_csv(y_test, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb8abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainClassifier(x_train_dir: InputPath(),y_train_dir: InputPath(), out_dir: OutputPath(str),classifierName:str):\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    if classifierName == \"DecisionTreeClassifier\":\n",
    "        from sklearn.tree import DecisionTreeClassifier as Classifier\n",
    "    elif classifierName == \"RandomForestClassifier\":\n",
    "        from sklearn.ensemble import RandomForestClassifier as Classifier\n",
    "    import pickle\n",
    "    \n",
    "    X_Train_NoShow = pd.read_csv(x_train_dir)\n",
    "    y_Train_NoShow = pd.read_csv(y_train_dir)\n",
    "    DT_class_Noshow = Classifier()\n",
    "    if classifierName == \"DecisionTreeClassifier\":\n",
    "        DT_class_Noshow = DT_class_Noshow.fit(X_Train_NoShow, y_Train_NoShow)\n",
    "    elif classifierName == \"RandomForestClassifier\":\n",
    "        DT_class_Noshow = DT_class_Noshow.fit(X_Train_NoShow, y_Train_NoShow.values.ravel())\n",
    "    \n",
    "    with open(out_dir, 'wb') as handle:\n",
    "        pickle.dump(DT_class_Noshow, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d843b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestClassifier(pickle_dir: InputPath(),x_test_dir: InputPath(),y_test_dir: InputPath(),classifierName: str) -> float:\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    if classifierName == \"DecisionTreeClassifier\":\n",
    "        from sklearn.tree import DecisionTreeClassifier as Classifier\n",
    "    elif classifierName == \"RandomForestClassifier\":\n",
    "        from sklearn.ensemble import RandomForestClassifier as Classifier\n",
    "    from sklearn import metrics\n",
    "    import pickle\n",
    "    \n",
    "    with open(pickle_dir, 'rb') as handle:\n",
    "        DTclass = pickle.load(handle)\n",
    "    X_Test_NoShow = pd.read_csv(x_test_dir)\n",
    "    y_Test_NoShow = pd.read_csv(y_test_dir)\n",
    "    \n",
    "    y_pred_DT_class = DTclass.predict(X_Test_NoShow)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_Test_NoShow, y_pred_DT_class, pos_label=1)\n",
    "    auc_dt = metrics.auc(fpr, tpr)\n",
    "    return float(auc_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11575579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmartScheduling(pickle_dir: InputPath(), data_dir: InputPath(),classifierName:str) -> str:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    import pickle\n",
    "    \n",
    "    with open(pickle_dir, 'rb') as handle:\n",
    "        DTclass = pickle.load(handle)\n",
    "        \n",
    "    NoShowData_NewExamples = pd.read_csv(data_dir)\n",
    "    #simulate 20 patient calls and predict their no-show risk\n",
    "    tot_patients = 20\n",
    "    deferred = 0 #initialize deferred to 0\n",
    "    patient_info = NoShowData_NewExamples.sample(tot_patients) #randomly sample 20 patient from the excel file for scheduling\n",
    "    risk_predictions = DTclass.predict(patient_info)\n",
    "\n",
    "    #model parameters:\n",
    "    tot_slots = 10 #total number of available slots for booking\n",
    "    DB = 0 #initilize total double-booked slots to 0\n",
    "    DB_max = 3 #only 3 slots can be double booked (30% of 10 slots)\n",
    "    deferred = 0 #initialize deferred appointments to zero\n",
    "\n",
    "    #initialize the appointment schedule\n",
    "    appointment_schedule = np.empty((tot_slots))\n",
    "    appointment_schedule[:] = np.NaN\n",
    "\n",
    "    appointment_schedule_DB = np.empty((tot_slots))\n",
    "    appointment_schedule_DB[:] = np.NaN\n",
    "\n",
    "    slot_capacity = np.zeros((tot_slots))\n",
    "    slot_capacity.fill(2) #no more than 2 patients per slot\n",
    "\n",
    "    slot_risktype = np.zeros((tot_slots)) #risk type of patient scheduled in a slot\n",
    "    slot_risktype.fill(2) \n",
    "\n",
    "    for p in range(tot_patients): #simulates sequential patient call-in. (i.e., for each patient calling for an appointment)\n",
    "        assignment = 0\n",
    "        if risk_predictions[p] == 1: #patient is low-risk\n",
    "            for slot in range(tot_slots): #start from beginning to search for a slot\n",
    "                if slot_capacity[slot] == 2 and assignment==0:\n",
    "                    appointment_schedule[slot] = p\n",
    "                    assignment = 1\n",
    "                    slot_risktype[slot] = 1 #risk type of patient single booked in this slot is low-risk\n",
    "                    slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "\n",
    "            if assignment == 0 and DB < DB_max: #scan for double-booking \n",
    "                for slot in range(tot_slots): #start from beginning to search for first feasible slot according to overbooking policy\n",
    "                    if slot_capacity[slot] == 1 and slot_risktype[slot] == 0 and assignment==0:\n",
    "                        appointment_schedule_DB[slot] = p\n",
    "                        assignment = 1\n",
    "                        slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "                        DB = DB + 1\n",
    "\n",
    "            if assignment == 0: #if patient is still not scheduled then assign it to \n",
    "                deferred = deferred+1\n",
    "\n",
    "\n",
    "        if risk_predictions[p] == 0: #patient is high-risk\n",
    "            for slot in range(tot_slots-1,-1,-1): #start from end to search for a slot\n",
    "                if slot_capacity[slot] == 2 and assignment==0:\n",
    "                    appointment_schedule[slot] = p\n",
    "                    assignment = 1\n",
    "                    slot_risktype[slot] = 0 #risk type of patient single booked in this slot is high-risk\n",
    "                    slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "\n",
    "            if assignment == 0 and DB < DB_max: #scan for double-booking \n",
    "                for slot in range(tot_slots-1,-1,-1): #start from beginning to search for first feasible slot according to overbooking policy\n",
    "                    if slot_capacity[slot] == 1 and slot_risktype[slot] == 1 and assignment==0:\n",
    "                        appointment_schedule_DB[slot] = p\n",
    "                        assignment = 1\n",
    "                        slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "                        DB = DB + 1\n",
    "\n",
    "            if assignment == 0: #if patient is still not scheduled then assign it to \n",
    "                deferred = deferred+1\n",
    "    with open('output.txt', 'w') as f:\n",
    "        print(f\"Schedule Generated: {appointment_schedule}\\nDoubleBooked Slots: {appointment_schedule_DB}\\nDeferred Patients: {deferred}\",file=f)\n",
    "        \n",
    "    return f\"Schedule Generated: {appointment_schedule}\\nDoubleBooked Slots: {appointment_schedule_DB}\\nDeferred Patients: {deferred}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d6a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImportantFeatures(pickle_dir: InputPath(), data_dir: InputPath(), classifierName: str ) -> str:\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "    import pickle\n",
    "    import sklearn\n",
    "    \n",
    "    with open(pickle_dir, 'rb') as handle:\n",
    "        DTclass = pickle.load(handle)\n",
    "    \n",
    "    NoShowData = pd.read_csv(data_dir)\n",
    "    features = list(NoShowData.columns[:-1])\n",
    "    importances = DTclass.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.title('Feature Importances')\n",
    "    r = \"\"\n",
    "    for i in indices:\n",
    "        r += f\"{features[i]}\\t:\\t{importances[i]}\\n\"\n",
    "            \n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "976a7ece-c425-408e-8038-583e526fa082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvalClassifiers(r1:float, r2:float, pickle1: InputPath(),pickle2: InputPath(), out_dir: OutputPath(str)):\n",
    "    import pickle\n",
    "    import sklearn\n",
    "    if r1>r2:\n",
    "        p = pickle1\n",
    "    else:\n",
    "        p = pickle2\n",
    "    with open(p, 'rb') as handle:\n",
    "        DTclass = pickle.load(handle)\n",
    "    with open(out_dir, 'wb') as handle:\n",
    "        pickle.dump(DTclass, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b080175",
   "metadata": {},
   "source": [
    "## Turning function to container_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1afed6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_op = comp.func_to_container_op(Preprocess,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas'])  \n",
    "\n",
    "selectFeatureAndSplit_op = comp.func_to_container_op(SelectFeatureAndSplit,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','sklearn'])  \n",
    "\n",
    "trainClassifier_op = comp.func_to_container_op(TrainClassifier,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','sklearn'])  \n",
    "\n",
    "testClassifier_op = comp.func_to_container_op(TestClassifier,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','sklearn','pickle-mixin'])  \n",
    "\n",
    "smartScheduling_op = comp.func_to_container_op(SmartScheduling,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','sklearn','numpy','pickle-mixin']) \n",
    "\n",
    "getImportantFeatures_op = comp.func_to_container_op(GetImportantFeatures,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','matplotlib','numpy','pickle-mixin','sklearn'])  \n",
    "\n",
    "evalClassifiers_op = comp.func_to_container_op(EvalClassifiers,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pickle-mixin','sklearn'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2fcad",
   "metadata": {},
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10cbdd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Smart Scheduling \",\n",
    "    description=\"Smart Outpatient Appointment Scheduling System\"\n",
    ")\n",
    "def smart_scheduling():\n",
    "    \n",
    "    # Pipeline's task 1 : Download and preprocess data\n",
    "    preprocess_task = preprocess_op(\"No-show_Data.csv\")\n",
    " \n",
    "    # Pipeline's task 2 : Feature Selection and Split Data into Training and Testing\n",
    "    selectFeatureAndSplit_task = selectFeatureAndSplit_op(preprocess_task.output)\n",
    "\n",
    "    # Pipeline's task 3 : Decision Tree Classififer Training\n",
    "    trainClassifier_op_DT_task = trainClassifier_op(selectFeatureAndSplit_task.outputs[\"x_train\"],selectFeatureAndSplit_task.outputs[\"y_train\"],\"DecisionTreeClassifier\")\n",
    " \n",
    "    # Pipeline's task 3 : Random Forest Classifier Training\n",
    "    trainClassifier_op_RF_task = trainClassifier_op(selectFeatureAndSplit_task.outputs[\"x_train\"],selectFeatureAndSplit_task.outputs[\"y_train\"],\"RandomForestClassifier\")\n",
    "\n",
    "    # Pipeline's task 4 : Test Decision Tree Classififer \n",
    "    testClassifier_op_DT_task = testClassifier_op(trainClassifier_op_DT_task.output,selectFeatureAndSplit_task.outputs[\"x_test\"],selectFeatureAndSplit_task.outputs[\"y_test\"],\"DecisionTreeClassifier\")\n",
    " \n",
    "    # Pipeline's task 4 : Test Random Forest Classifier \n",
    "    testClassifier_op_RF_task = testClassifier_op(trainClassifier_op_RF_task.output,selectFeatureAndSplit_task.outputs[\"x_test\"],selectFeatureAndSplit_task.outputs[\"y_test\"],\"RandomForestClassifier\")\n",
    "    \n",
    "    evalClassifiers_task = evalClassifiers_op(testClassifier_op_DT_task.output,testClassifier_op_RF_task.output,trainClassifier_op_DT_task.output,trainClassifier_op_RF_task.output)\n",
    "    # Select Best Classifier \n",
    "    if evalClassifiers_task.output == trainClassifier_op_DT_task.output:\n",
    "        best_classifier = \"DecisionTreeClassifier\"\n",
    "    else:\n",
    "        best_classifier = \"RandomForestClassifier\"\n",
    "        \n",
    "    # Pipeline's task 5 : Identify Variables Important for Predicting No-shows\n",
    "    getImportantFeatures_task = getImportantFeatures_op(evalClassifiers_task.output,preprocess_task.output, best_classifier)\n",
    "    \n",
    "    # Pipeline's task 6 : Predict New Examples\n",
    "    preprocess_new_task = preprocess_op(\"No-show_Data_Testing.csv\")\n",
    "\n",
    "    # Pipeline's task 7 : Smart Scheduling according to prediction\n",
    "    smartScheduling_op(evalClassifiers_task.output, preprocess_new_task.output, best_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad22a758",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc8cdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(smart_scheduling, \"smart_scheduling.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23515c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan 1337 8415 Sep 21 04:24 ./smart_scheduling.zip\n"
     ]
    }
   ],
   "source": [
    "!ls -al ./smart_scheduling.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8732e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./smart_scheduling.zip\n",
      "  inflating: pipeline.yaml           \n"
     ]
    }
   ],
   "source": [
    "!unzip -o ./smart_scheduling.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2105e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0649d396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/2e4dd334-85a1-4145-9dd7-bada367bb813\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"Smart Scheduling Experiment 3\"\n",
    "client = kfp.Client()\n",
    "try:\n",
    "    experiment = client.get_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "except:\n",
    "    experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "my_run = client.run_pipeline(experiment.id, \"smart-scheduling-pipeline\", \"smart_scheduling.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "deploy_config": {},
   "docker_image": "gcr.io/arrikto/jupyter-kale-py38@sha256:b7e923046b834491fb5fd90850940cb3b57ba5aedb7d558757d9848db6cb28eb",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": true,
   "storage_class_name": "",
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "dddd-smart-schedule-workspace-jxvh2",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
